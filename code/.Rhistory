dfTrain_fact$Sector <- as.numeric(as.factor(dfTrain_fact$Sector))
str(dfTrain_fact)
# Creamos nuevo data frame sobre el que trabajaremos para obtener todas las variables de tipo numérico, factorizando las variables categóricas.
dfTrain_fact <- dfTrain
# Seleccionamos las variables Age_lm y Age_mean para proceder con su discretización
x_lm <- dfTrain_fact[,13]
x_mean <- dfTrain_fact[,14]
# k-means clustering to discretize Age based on Age with NAN values replaced by Logistic regression
hist(x_lm, breaks = 40, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 4, onlycuts = TRUE), col = "red")
# k-means clustering to discretize Age based on Age with NAN values replaced by mean
hist(x_mean, breaks = 40, main = "Clustering")
abline(v = discretize(x_mean, method = "cluster", breaks = 4, onlycuts = TRUE), col = "red")
discretize(x_lm, method = "cluster", breaks = 4, onlycuts = TRUE)
table(discretize(x_mean, method = "cluster", breaks = 4, onlycuts = TRUE))
### discretize all numeric columns differently
dfTrain_fact$AgeCat_lm <- cut(dfTrain_fact$Age_lm, c(0,2,13,22,60,80), labels=c(1:5))
dfTrain_fact$AgeCat_mean <- cut(dfTrain_fact$Age_mean, c(0,2,13,22,60,80), labels=c(1:5))
# Verificamos la estructura del juego de datos y factorizamos las variables categóricas (Sex, Embarked y Sector(obtenida a partir de Cabin))
str(dfTrain_fact)
dfTrain_fact$Sex <- as.numeric(as.factor(dfTrain_fact$Sex))
dfTrain_fact$Embarked <- as.numeric(as.factor(dfTrain_fact$Embarked))
dfTrain_fact$Sector <- as.numeric(as.factor(dfTrain_fact$Sector))
dfTrain_fact <- dfTrain_fact[-c(4,6,9,11,13:14)]
str(dfTrain_fact)
# Creamos nuevo data frame sobre el que trabajaremos para obtener todas las variables de tipo numérico, factorizando las variables categóricas.
dfTrain_fact <- dfTrain
# Seleccionamos las variables Age_lm y Age_mean para proceder con su discretización
x_lm <- dfTrain_fact[,13]
x_mean <- dfTrain_fact[,14]
# k-means clustering to discretize Age based on Age with NAN values replaced by Logistic regression
hist(x_lm, breaks = 40, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 4, onlycuts = TRUE), col = "red")
# k-means clustering to discretize Age based on Age with NAN values replaced by mean
hist(x_mean, breaks = 40, main = "Clustering")
abline(v = discretize(x_mean, method = "cluster", breaks = 4, onlycuts = TRUE), col = "red")
discretize(x_lm, method = "cluster", breaks = 4, onlycuts = TRUE)
discretize(x_mean, method = "cluster", breaks = 4, onlycuts = TRUE)
### discretize all numeric columns differently
dfTrain_fact$AgeCat_lm <- cut(dfTrain_fact$Age_lm, c(0,2,13,22,60,80), labels=c(1:5))
dfTrain_fact$AgeCat_mean <- cut(dfTrain_fact$Age_mean, c(0,2,13,22,60,80), labels=c(1:5))
# Verificamos la estructura del juego de datos y factorizamos las variables categóricas (Sex, Embarked y Sector(obtenida a partir de Cabin))
str(dfTrain_fact)
dfTrain_fact$Sex <- as.numeric(as.factor(dfTrain_fact$Sex))
dfTrain_fact$Embarked <- as.numeric(as.factor(dfTrain_fact$Embarked))
dfTrain_fact$Sector <- as.numeric(as.factor(dfTrain_fact$Sector))
dfTrain_fact <- dfTrain_fact[-c(4,6,9,11,13:14)]
str(dfTrain_fact)
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
# Cargamos paquete TIDYVERSE que engloba a otros paquetes que nos permiten llevar a cabo la importación, transformación, visualización, modelado y comunicación de datos/información
if(!require(tidyverse)){
install.packages('tidyverse', repos='http://cran.us.r-project.org')
}
library(tidyverse)
# Cargamos paquete PSYCH
if(!require(psych)){
install.packages('psych', repos='http://cran.us.r-project.org')
}
library(psych)
# Cargamos paquete reticulate
if(!require(reticulate)){
install.packages('reticulate', repos='http://cran.us.r-project.org')
}
library(reticulate)
# Cargamos paquete CORRPLOT
if(!require(corrplot)){
install.packages('corrplot', repos='http://cran.us.r-project.org')
}
library(corrplot)
# Cargamos paquete DESCTOOLS
if(!require(DescTools)){
install.packages('DescTools', repos='http://cran.us.r-project.org')
}
library(DescTools)
# Cargamos paquete ARULES
if(!require(arules)){
install.packages('arules', repos='http://cran.us.r-project.org')
}
library(arules)
# Cargamos paquete CLUSTER
if(!require(cluster)){
install.packages('cluster', repos='http://cran.us.r-project.org')
}
library(cluster)
# Cargamos paquete MCLUST
if(!require(mclust)){
install.packages('mclust', repos='http://cran.us.r-project.org')
}
library(mclust)
# Cargamos paquete TIDYVERSE que engloba a otros paquetes que nos permiten llevar a cabo la importación, transformación, visualización, modelado y comunicación de datos/información
if(!require(tidyverse)){
install.packages('tidyverse', repos='http://cran.us.r-project.org')
}
library(tidyverse)
# Cargamos paquete PSYCH
if(!require(psych)){
install.packages('psych', repos='http://cran.us.r-project.org')
}
library(psych)
# Cargamos paquete reticulate
if(!require(reticulate)){
install.packages('reticulate', repos='http://cran.us.r-project.org')
}
library(reticulate)
# Cargamos paquete CORRPLOT
if(!require(corrplot)){
install.packages('corrplot', repos='http://cran.us.r-project.org')
}
library(corrplot)
# Cargamos paquete DESCTOOLS
if(!require(DescTools)){
install.packages('DescTools', repos='http://cran.us.r-project.org')
}
library(DescTools)
# Cargamos paquete ARULES
if(!require(arules)){
install.packages('arules', repos='http://cran.us.r-project.org')
}
library(arules)
# Cargamos paquete CLUSTER
if(!require(cluster)){
install.packages('cluster', repos='http://cran.us.r-project.org')
}
library(cluster)
# Cargamos paquete MCLUST
if(!require(mclust)){
install.packages('mclust', repos='http://cran.us.r-project.org')
}
library(mclust)
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:5, Silh = avgS)
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:50, Silh = avgS)
# k-means clustering to discretize Fare
hist(x_lm, breaks = 40, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 4, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:50, Silh = avgS)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 40, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:50, Silh = avgS)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 2, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:50, Silh = avgS)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:50) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:50, Silh = avgS)
unique(dfTrain_fact$Fare)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,7]))
}
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,7]))
}
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:5, Silh = avgS)
unique(dfTrain_fact$Fare)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:5, Silh = avgS)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(x_lm, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,2,13,22,60,80), labels=c(1:5))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:5, Silh = avgS)
# k-means clustering to discretize Fare
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(dfTrain_fact$Fare, method = "cluster", breaks = 2, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fate, c(0,50,200,512), labels=c(1:3))
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,50,200,512), labels=c(1:3))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:5, Silh = avgS)
# k-means clustering para discretizar la variable Fare. Aunque parece que según el coeficiente de la silueta 2 sería la mejor opción para cantidad de grupos, probamos 3 porque parece más ajustado a la realidad socioeconómica de la época
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(dfTrain_fact$Fare, method = "cluster", breaks = 3, onlycuts = TRUE), col = "red")
dfTrain_fact$Fare_cat <- cut(dfTrain_fact$Fare, c(0,50,200,512), labels=c(1:3))
set.seed(0911)
d <- dist(dfTrain_fact$Fare)
avgS <- c()
for(k in 2:5) {
cl <- kmeans(dfTrain_fact$Fare, centers = k, iter.max = 200)
s <- silhouette(cl$cluster, d)
avgS <- c(avgS, mean(s[,3]))
}
data.frame(nClus = 2:5, Silh = avgS)
# k-means clustering para discretizar la variable Fare. Aunque parece que según el coeficiente de la silueta 2 sería la mejor opción para cantidad de grupos, probamos 3 porque parece más ajustado a la realidad socioeconómica de la época
hist(dfTrain_fact$Fare, breaks = 10, main = "Clustering")
abline(v = discretize(dfTrain_fact$Fare, method = "cluster", breaks = 3, onlycuts = TRUE), col = "red")
dfTrain_fact <- dfTrain_fact[-7]
View(dfTrain)
View(dfTrain_fact)
knitr::opts_chunk$set(eval=T, echo=T)
write.csv(dfTrain_cat, "dfTrain_cat.csv")
knitr::opts_chunk$set(eval=T, echo=T)
# Cargamos paquete TIDYVERSE que engloba a otros paquetes que nos permiten llevar a cabo la importación, transformación, visualización, modelado y comunicación de datos/información
if(!require(tidyverse)){
install.packages('tidyverse', repos='http://cran.us.r-project.org')
}
library(tidyverse)
# Cargamos paquete PSYCH que agrupa funciones  utilizadas en psicología.
if(!require(psych)){
install.packages('psych', repos='http://cran.us.r-project.org')
}
library(psych)
# Cargamos paquete reticulate proporciona un conjunto de  herramientas para integrar código Python y R.
if(!require(reticulate)){
install.packages('reticulate', repos='http://cran.us.r-project.org')
}
library(reticulate)
# Cargamos paquete CORRPLOT nos permite la representación gráfica de una matriz de correlación, así como nos proporciona algunos algoritmos para hacer reordenamiento de la matriz
if(!require(corrplot)){
install.packages('corrplot', repos='http://cran.us.r-project.org')
}
library(corrplot)
# Cargamos paquete DESCTOOLS que proporciona una colección de funciones estadísticas básicas para la descripción de datos
if(!require(DescTools)){
install.packages('DescTools', repos='http://cran.us.r-project.org')
}
library(DescTools)
# Cargamos paquete ARULES que proporciona la infraestructura para representar, manipular y analizar los datos y patrones de las transacciones (conjuntos de elementos frecuentes y reglas de asociación)
if(!require(arules)){
install.packages('arules', repos='http://cran.us.r-project.org')
}
library(arules)
# Cargamos paquete CLUSTER que nos proporciona métodos de análisis de clusters (Agrupaciones)
if(!require(cluster)){
install.packages('cluster', repos='http://cran.us.r-project.org')
}
library(cluster)
# Cargamos paquete MCLUST que nos proporciona herraminetas para la agrupación, clasificación y estimación de densidad
if(!require(mclust)){
install.packages('mclust', repos='http://cran.us.r-project.org')
}
library(mclust)
#Cargamos el paquete GGALLY, que amplía 'GGPLOT2' añadiendo varias funciones para reducir la complejidad de la combinación de objetos geométricos con datos transformados.
if(!require(GGally)){
install.packages('GGally', repos='http://cran.us.r-project.org')
}
library(GGally)
#Cargamos el paquete RPART paquete que nos permite el particionado recursivo y el uso de árboles de regresión
if(!require(rpart)){
install.packages('rpart', repos='http://cran.us.r-project.org')
}
library(rpart)
#Cargamos el paquete IPRED que Mejora de los modelos de predicción mediante la clasificación indirecta y el empaquetamiento (bagging) para los problemas de clasificación, regresión y supervivencia, así como el remuestreo basado en los estimadores del error de predicción.
if(!require(ipred)){
install.packages('ipred', repos='http://cran.us.r-project.org')
}
library(ipred)
#Cargamos el paquete VIM que introduce nuevas herramientas para la visualización de los valores perdidos y/o imputados
if(!require(VIM)){
install.packages('VIM', repos='http://cran.us.r-project.org')
}
library(VIM)
#Cargamos el paquete NORTEST que agrupa 5 pruebas 'Omnibus' para probar la hipótesis compuesta de la normalidad.
if(!require(nortest)){
install.packages('nortest', repos='http://cran.us.r-project.org')
}
library(nortest)
#Cargamos el paquete CARET(Classification And REgression Training) es un conjunto de funciones que intentan racionalizar el proceso de creación de modelos predictivos
if(!require(caret)){
install.packages('caret', repos='http://cran.us.r-project.org')
}
library(caret)
#Cargamos el paquete RANDOMFOREST que nos permite la aplicación de Clasificación y regresión mediante el algoritmo de random forest
if(!require(randomForest)){
install.packages('randomForest', repos='http://cran.us.r-project.org')
}
library(randomForest)
#Cargamos el paquete GGRAPH, que es una extensión de la API de ggplot2 adaptada a las visualizaciones de gráficos y proporciona el mismo enfoque flexible para construir gráficos capa por capa.
if(!require(ggraph)){
install.packages('ggraph', repos='http://cran.us.r-project.org')
}
library(ggraph)
#Cargamos el paquete GGRAPH, que nos proporciona Rutinas para gráficos simples y análisis de redes.
if(!require(igraph)){
install.packages('igraph', repos='http://cran.us.r-project.org')
}
library(igraph)
# Instalamos paquete PANDAS para ser usado en los fragmentos de código Python
if(!require(pandas)){
py_install("pandas")
}
# Instalamos paquete MATPLOTLIB para ser usado en los fragmentos de código Python
if(!require(matplotlib)){
py_install("matplotlib")
}
# Instalamos paquete SEABORN para ser usado en los fragmentos de código Python
if(!require(seaborn)){
py_install("seaborn")
}
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("../titanic/train.csv",header=T, sep=",")
# Visualizamos las 6 primeras filas, y las 6 últimas, del nuevo dataset
head(train)
tail(train)
knitr::opts_chunk$set(eval=T, echo=T)
# Cargamos paquete TIDYVERSE que engloba a otros paquetes que nos permiten llevar a cabo la importación, transformación, visualización, modelado y comunicación de datos/información
if(!require(tidyverse)){
install.packages('tidyverse', repos='http://cran.us.r-project.org')
}
library(tidyverse)
# Cargamos paquete PSYCH que agrupa funciones  utilizadas en psicología.
if(!require(psych)){
install.packages('psych', repos='http://cran.us.r-project.org')
}
library(psych)
# Cargamos paquete reticulate proporciona un conjunto de  herramientas para integrar código Python y R.
if(!require(reticulate)){
install.packages('reticulate', repos='http://cran.us.r-project.org')
}
library(reticulate)
# Cargamos paquete CORRPLOT nos permite la representación gráfica de una matriz de correlación, así como nos proporciona algunos algoritmos para hacer reordenamiento de la matriz
if(!require(corrplot)){
install.packages('corrplot', repos='http://cran.us.r-project.org')
}
library(corrplot)
# Cargamos paquete DESCTOOLS que proporciona una colección de funciones estadísticas básicas para la descripción de datos
if(!require(DescTools)){
install.packages('DescTools', repos='http://cran.us.r-project.org')
}
library(DescTools)
# Cargamos paquete ARULES que proporciona la infraestructura para representar, manipular y analizar los datos y patrones de las transacciones (conjuntos de elementos frecuentes y reglas de asociación)
if(!require(arules)){
install.packages('arules', repos='http://cran.us.r-project.org')
}
library(arules)
# Cargamos paquete CLUSTER que nos proporciona métodos de análisis de clusters (Agrupaciones)
if(!require(cluster)){
install.packages('cluster', repos='http://cran.us.r-project.org')
}
library(cluster)
# Cargamos paquete MCLUST que nos proporciona herraminetas para la agrupación, clasificación y estimación de densidad
if(!require(mclust)){
install.packages('mclust', repos='http://cran.us.r-project.org')
}
library(mclust)
#Cargamos el paquete GGALLY, que amplía 'GGPLOT2' añadiendo varias funciones para reducir la complejidad de la combinación de objetos geométricos con datos transformados.
if(!require(GGally)){
install.packages('GGally', repos='http://cran.us.r-project.org')
}
library(GGally)
#Cargamos el paquete RPART paquete que nos permite el particionado recursivo y el uso de árboles de regresión
if(!require(rpart)){
install.packages('rpart', repos='http://cran.us.r-project.org')
}
library(rpart)
#Cargamos el paquete IPRED que Mejora de los modelos de predicción mediante la clasificación indirecta y el empaquetamiento (bagging) para los problemas de clasificación, regresión y supervivencia, así como el remuestreo basado en los estimadores del error de predicción.
if(!require(ipred)){
install.packages('ipred', repos='http://cran.us.r-project.org')
}
library(ipred)
#Cargamos el paquete VIM que introduce nuevas herramientas para la visualización de los valores perdidos y/o imputados
if(!require(VIM)){
install.packages('VIM', repos='http://cran.us.r-project.org')
}
library(VIM)
#Cargamos el paquete NORTEST que agrupa 5 pruebas 'Omnibus' para probar la hipótesis compuesta de la normalidad.
if(!require(nortest)){
install.packages('nortest', repos='http://cran.us.r-project.org')
}
library(nortest)
#Cargamos el paquete CARET(Classification And REgression Training) es un conjunto de funciones que intentan racionalizar el proceso de creación de modelos predictivos
if(!require(caret)){
install.packages('caret', repos='http://cran.us.r-project.org')
}
library(caret)
#Cargamos el paquete RANDOMFOREST que nos permite la aplicación de Clasificación y regresión mediante el algoritmo de random forest
if(!require(randomForest)){
install.packages('randomForest', repos='http://cran.us.r-project.org')
}
library(randomForest)
#Cargamos el paquete GGRAPH, que es una extensión de la API de ggplot2 adaptada a las visualizaciones de gráficos y proporciona el mismo enfoque flexible para construir gráficos capa por capa.
if(!require(ggraph)){
install.packages('ggraph', repos='http://cran.us.r-project.org')
}
