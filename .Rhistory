tibble::rownames_to_column() %>%
# make leaf split points to NA, so the 0s won't get plotted
mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))
# prepare data frame for graph
graph_frame <- data.frame(from = rep(tree$rowname, 2),
to = c(tree$`left daughter`, tree$`right daughter`))
# convert to graph and delete the last node that we don't want to plot
graph <- graph_from_data_frame(graph_frame) %>%
delete_vertices("0")
# set node labels
V(graph)$node_label <- gsub("_", " ", as.character(tree$`split var`))
V(graph)$leaf_label <- as.character(tree$prediction)
V(graph)$split <- as.character(round(tree$`split point`, digits = 2))
# plot
plot <- ggraph(graph, 'dendrogram') +
theme_bw() +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = node_label), na.rm = TRUE, repel = TRUE) +
geom_node_label(aes(label = split), vjust = 2.5, na.rm = TRUE, fill = "white") +
geom_node_label(aes(label = leaf_label, fill = leaf_label), na.rm = TRUE,
repel = TRUE, colour = "white", fontface = "bold", show.legend = FALSE) +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
panel.background = element_blank(),
plot.background = element_rect(fill = "white"),
panel.border = element_blank(),
axis.line = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
plot.title = element_text(size = 30))
print(plot)
}
tree_num <- which(train.rpart$finalModel$forest$ndbigtree == min(train.rpart$finalModel$forest$ndbigtree))
tree_func(final_model = train.rpart$finalModel, tree_num)
#Función https://stackoverrun.com/es/q/6546365
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title('CONFUSION MATRIX', cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Class1', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Class2', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Class1', cex=1.2, srt=90)
text(140, 335, 'Class2', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
# add in the accuracy information
text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
cm <- confusionMatrix(pred, train.rpart$trainingData$.outcome, mode = "everything")
draw_confusion_matrix(cm)
dfTrain_cat$child <- cut(dfTrain$Age, c(0,13,100), labels=c("Child", "Adult"))
dfTrain_cat$child[dfTrain_cat$child == "1"] <- "Child"
tinytex::install_tinytex()
knitr::opts_chunk$set(eval=T, echo=T)
# Cargamos paquete TIDYVERSE que engloba a otros paquetes que nos permiten llevar a cabo la importación, transformación, visualización, modelado y comunicación de datos/información
if(!require(tidyverse)){
install.packages('tidyverse', repos='http://cran.us.r-project.org')
}
library(tidyverse)
# Cargamos paquete PSYCH que agrupa funciones  utilizadas en psicología.
if(!require(psych)){
install.packages('psych', repos='http://cran.us.r-project.org')
}
library(psych)
# Cargamos paquete reticulate proporciona un conjunto de  herramientas para integrar código Python y R.
if(!require(reticulate)){
install.packages('reticulate', repos='http://cran.us.r-project.org')
}
library(reticulate)
# Cargamos paquete CORRPLOT nos permite la representación gráfica de una matriz de correlación, así como nos proporciona algunos algoritmos para hacer reordenamiento de la matriz
if(!require(corrplot)){
install.packages('corrplot', repos='http://cran.us.r-project.org')
}
library(corrplot)
# Cargamos paquete DESCTOOLS que proporciona una colección de funciones estadísticas básicas para la descripción de datos
if(!require(DescTools)){
install.packages('DescTools', repos='http://cran.us.r-project.org')
}
library(DescTools)
# Cargamos paquete ARULES que proporciona la infraestructura para representar, manipular y analizar los datos y patrones de las transacciones (conjuntos de elementos frecuentes y reglas de asociación)
if(!require(arules)){
install.packages('arules', repos='http://cran.us.r-project.org')
}
library(arules)
# Cargamos paquete CLUSTER que nos proporciona métodos de análisis de clusters (Agrupaciones)
if(!require(cluster)){
install.packages('cluster', repos='http://cran.us.r-project.org')
}
library(cluster)
# Cargamos paquete MCLUST que nos proporciona herraminetas para la agrupación, clasificación y estimación de densidad
if(!require(mclust)){
install.packages('mclust', repos='http://cran.us.r-project.org')
}
library(mclust)
#Cargamos el paquete GGALLY, que amplía 'GGPLOT2' añadiendo varias funciones para reducir la complejidad de la combinación de objetos geométricos con datos transformados.
if(!require(GGally)){
install.packages('GGally', repos='http://cran.us.r-project.org')
}
library(GGally)
#Cargamos el paquete RPART paquete que nos permite el particionado recursivo y el uso de árboles de regresión
if(!require(rpart)){
install.packages('rpart', repos='http://cran.us.r-project.org')
}
library(rpart)
#Cargamos el paquete IPRED que Mejora de los modelos de predicción mediante la clasificación indirecta y el empaquetamiento (bagging) para los problemas de clasificación, regresión y supervivencia, así como el remuestreo basado en los estimadores del error de predicción.
if(!require(ipred)){
install.packages('ipred', repos='http://cran.us.r-project.org')
}
library(ipred)
#Cargamos el paquete VIM que introduce nuevas herramientas para la visualización de los valores perdidos y/o imputados
if(!require(VIM)){
install.packages('VIM', repos='http://cran.us.r-project.org')
}
library(VIM)
#Cargamos el paquete NORTEST que agrupa 5 pruebas 'Omnibus' para probar la hipótesis compuesta de la normalidad.
if(!require(nortest)){
install.packages('nortest', repos='http://cran.us.r-project.org')
}
library(nortest)
#Cargamos el paquete CARET(Classification And REgression Training) es un conjunto de funciones que intentan racionalizar el proceso de creación de modelos predictivos
if(!require(caret)){
install.packages('caret', repos='http://cran.us.r-project.org')
}
library(caret)
#Cargamos el paquete RANDOMFOREST que nos permite la aplicación de Clasificación y regresión mediante el algoritmo de random forest
if(!require(randomForest)){
install.packages('randomForest', repos='http://cran.us.r-project.org')
}
library(randomForest)
#Cargamos el paquete GGRAPH, que es una extensión de la API de ggplot2 adaptada a las visualizaciones de gráficos y proporciona el mismo enfoque flexible para construir gráficos capa por capa.
if(!require(ggraph)){
install.packages('ggraph', repos='http://cran.us.r-project.org')
}
library(ggraph)
#Cargamos el paquete GGRAPH, que nos proporciona Rutinas para gráficos simples y análisis de redes.
if(!require(igraph)){
install.packages('igraph', repos='http://cran.us.r-project.org')
}
library(igraph)
# Instalamos paquete PANDAS para ser usado en los fragmentos de código Python
if(!require(pandas)){
py_install("pandas")
}
# Instalamos paquete MATPLOTLIB para ser usado en los fragmentos de código Python
if(!require(matplotlib)){
py_install("matplotlib")
}
# Instalamos paquete SEABORN para ser usado en los fragmentos de código Python
if(!require(seaborn)){
py_install("seaborn")
}
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Visualizamos las 6 primeras filas, y las 6 últimas, del nuevo dataset
head(train)
tail(train)
knitr::opts_chunk$set(eval=T, echo=T)
# Cargamos paquete TIDYVERSE que engloba a otros paquetes que nos permiten llevar a cabo la importación, transformación, visualización, modelado y comunicación de datos/información
if(!require(tidyverse)){
install.packages('tidyverse', repos='http://cran.us.r-project.org')
}
library(tidyverse)
# Cargamos paquete PSYCH que agrupa funciones  utilizadas en psicología.
if(!require(psych)){
install.packages('psych', repos='http://cran.us.r-project.org')
}
library(psych)
# Cargamos paquete reticulate proporciona un conjunto de  herramientas para integrar código Python y R.
if(!require(reticulate)){
install.packages('reticulate', repos='http://cran.us.r-project.org')
}
library(reticulate)
# Cargamos paquete CORRPLOT nos permite la representación gráfica de una matriz de correlación, así como nos proporciona algunos algoritmos para hacer reordenamiento de la matriz
if(!require(corrplot)){
install.packages('corrplot', repos='http://cran.us.r-project.org')
}
library(corrplot)
# Cargamos paquete DESCTOOLS que proporciona una colección de funciones estadísticas básicas para la descripción de datos
if(!require(DescTools)){
install.packages('DescTools', repos='http://cran.us.r-project.org')
}
library(DescTools)
# Cargamos paquete ARULES que proporciona la infraestructura para representar, manipular y analizar los datos y patrones de las transacciones (conjuntos de elementos frecuentes y reglas de asociación)
if(!require(arules)){
install.packages('arules', repos='http://cran.us.r-project.org')
}
library(arules)
# Cargamos paquete CLUSTER que nos proporciona métodos de análisis de clusters (Agrupaciones)
if(!require(cluster)){
install.packages('cluster', repos='http://cran.us.r-project.org')
}
library(cluster)
# Cargamos paquete MCLUST que nos proporciona herraminetas para la agrupación, clasificación y estimación de densidad
if(!require(mclust)){
install.packages('mclust', repos='http://cran.us.r-project.org')
}
library(mclust)
#Cargamos el paquete GGALLY, que amplía 'GGPLOT2' añadiendo varias funciones para reducir la complejidad de la combinación de objetos geométricos con datos transformados.
if(!require(GGally)){
install.packages('GGally', repos='http://cran.us.r-project.org')
}
library(GGally)
#Cargamos el paquete RPART paquete que nos permite el particionado recursivo y el uso de árboles de regresión
if(!require(rpart)){
install.packages('rpart', repos='http://cran.us.r-project.org')
}
library(rpart)
#Cargamos el paquete IPRED que Mejora de los modelos de predicción mediante la clasificación indirecta y el empaquetamiento (bagging) para los problemas de clasificación, regresión y supervivencia, así como el remuestreo basado en los estimadores del error de predicción.
if(!require(ipred)){
install.packages('ipred', repos='http://cran.us.r-project.org')
}
library(ipred)
#Cargamos el paquete VIM que introduce nuevas herramientas para la visualización de los valores perdidos y/o imputados
if(!require(VIM)){
install.packages('VIM', repos='http://cran.us.r-project.org')
}
library(VIM)
#Cargamos el paquete NORTEST que agrupa 5 pruebas 'Omnibus' para probar la hipótesis compuesta de la normalidad.
if(!require(nortest)){
install.packages('nortest', repos='http://cran.us.r-project.org')
}
library(nortest)
#Cargamos el paquete CARET(Classification And REgression Training) es un conjunto de funciones que intentan racionalizar el proceso de creación de modelos predictivos
if(!require(caret)){
install.packages('caret', repos='http://cran.us.r-project.org')
}
library(caret)
#Cargamos el paquete RANDOMFOREST que nos permite la aplicación de Clasificación y regresión mediante el algoritmo de random forest
if(!require(randomForest)){
install.packages('randomForest', repos='http://cran.us.r-project.org')
}
library(randomForest)
#Cargamos el paquete GGRAPH, que es una extensión de la API de ggplot2 adaptada a las visualizaciones de gráficos y proporciona el mismo enfoque flexible para construir gráficos capa por capa.
if(!require(ggraph)){
install.packages('ggraph', repos='http://cran.us.r-project.org')
}
library(ggraph)
#Cargamos el paquete GGRAPH, que nos proporciona Rutinas para gráficos simples y análisis de redes.
if(!require(igraph)){
install.packages('igraph', repos='http://cran.us.r-project.org')
}
library(igraph)
# Instalamos paquete PANDAS para ser usado en los fragmentos de código Python
if(!require(pandas)){
py_install("pandas")
}
# Instalamos paquete MATPLOTLIB para ser usado en los fragmentos de código Python
if(!require(matplotlib)){
py_install("matplotlib")
}
# Instalamos paquete SEABORN para ser usado en los fragmentos de código Python
if(!require(seaborn)){
py_install("seaborn")
}
# Carga de los datos de entrenamiento desde el archivo csv a un nuevo dataframe llamado train
train <- read.csv("./titanic/train.csv",header=T, sep=",")
# Visualizamos las 6 primeras filas, y las 6 últimas, del nuevo dataset
head(train)
tail(train)
#Creamos un nuevo set, copia del anterior, que usaremos en adelante. De esta manera, si necesitamos volver a utilizar datos originales sin tratar no deberemos volver a cargar el fichero.
dfTrain <- train
# Se utiliza la función sumary para
summary(dfTrain)
describe(dfTrain)
# Se elimina de este estudio las variables name, cabin y tiket ya que al ser nominales cuentan con excesivos valores diferentes y no aportan valor en este análisis
ds_aux = subset(dfTrain, select = - c(Name,Ticket,Cabin) )
ggpairs(ds_aux, lower = list(continuous = "smooth"),
diag = list(continuous = "bar"), axisLabels = "none")
# Transfomamos el dataset de R a un dataframe de Pandas (python)
pdTrain <- r_to_py(dfTrain)
# Mediante observación directa del fichero csv y las información obtenida en el estudio ya realizado, se observa que los campos Cabin y Embarked contienen valores desconocidos representados con "".
# Número de valores "" contenidos por la variable Cabin
cat("Numero de valores nulos en Cavin:", NROW(dfTrain$Cabin[dfTrain$Cabin == ""]))
# Valores únicos para Embarked
cat("Valores únicos para Embarked:")
unique(dfTrain$Embarked)
# Valores nulos en enbarked
cat("Numero de valores nulos para Embarked: ",NROW(dfTrain$Embarked[dfTrain$Embarked == ""]))
#Recodificamos como valores desconocidos aquellos valores == "" en los campos mencionados anteriormente
dfTrain$Cabin[dfTrain$Cabin == ""] <- NA
dfTrain$Embarked[dfTrain$Embarked == ""] <- NA
# Estadísticas de valores vacíos
colSums(is.na(dfTrain))
dfTrain$Sector[!is.na(dfTrain$Cabin)] <- as.factor(substr(dfTrain[!is.na(dfTrain$Cabin),]$Cabin,1,1))
dfTrain$Sector[is.na(dfTrain$Cabin)] <- "0"
#dfTrain$Sector
# Creamos nuevo data frame sobre el que trabajaremos para obtener todas las variables de tipo numérico, factorizando las variables categóricas.
dfTrain_cat <- dfTrain
# Verificamos la estructura del juego de datos y factorizamos las variables categóricas (Sex, Embarked y Sector(obtenida a partir de Cabin))
str(dfTrain_cat)
# Discretizamos la edad creando 5 rangos de edades: Bebé(0-3], Infante(3-13], joven(13-29), Adulto(29,60], Anciano(60,100]
dfTrain_cat$Age <- cut(dfTrain_cat$Age, c(0,3,13,29,60,100), labels=c(1:5))
# Eliminamos del dataset las variables Ticket y Cabin
dfTrain_cat <- dfTrain_cat[-c(9,11)]
# Creamos nuevo data frame sobre el que trabajaremos para obtener todas las variables de tipo numérico, factorizando las variables categóricas.
dfTrain_cat$Sex <- as.factor(dfTrain_cat$Sex)
dfTrain_cat$Embarked <- as.factor(dfTrain_cat$Embarked)
dfTrain_cat$Age <- as.factor(dfTrain_cat$Age)
dfTrain_cat$Pclass <- as.factor(dfTrain_cat$Pclass)
dfTrain_cat$SibSp <- as.factor(dfTrain_cat$SibSp)
dfTrain_cat$Parch <- as.factor(dfTrain_cat$Parch)
dfTrain_cat$Sector<- as.factor(dfTrain_cat$Sector)
# Eliminamos del dataset la variable Name
dfTrain_cat <- dfTrain_cat[-4]
# Eliminamos del dataset la variable PassengerId
dfTrain_cat <- dfTrain_cat[-1]
str(dfTrain_cat)
dfTrain_cat$Embarked <- kNN(dfTrain_cat)$Embarked
colSums(is.na(dfTrain_cat))
dfTrain_cat_age <- dfTrain_cat[!is.na(dfTrain_cat$Age),]
model_age_cat <- lm(as.numeric(Age)~as.numeric(Pclass) + as.numeric(SibSp) + as.numeric(Parch), data = dfTrain_cat_age)
summary(model_age_cat)
## 80% of the sample size
smp_size <- floor(0.80 * nrow(dfTrain_cat_age))
## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(dfTrain_cat_age)), size = smp_size)
train <- dfTrain_cat_age[train_ind, ]
test <- dfTrain_cat_age[-train_ind, ]
# Usamos Bagging nos permite combinar los resultados de varios modelos de clasificación para conseguir mejores resultados.
fit <- bagging(Age~.-Sector, data=train)
# Predecimos los valores del test
pred <- predict(fit, test)
#t = table(pred, test$Age)
confusionMatrix(pred, test$Age)
dfTrain_cat$Age <- kNN(dfTrain_cat)$Age
colSums(is.na(dfTrain_cat))
# Creamos nuevo data frame sobre el que trabajaremos para obtener todas las variables de tipo numérico, factorizando las variables categóricas.
dfTrain_fact <- dfTrain_cat
# Verificamos la estructura del juego de datos y factorizamos las variables categóricas (Sex, Embarked y Sector(obtenida a partir de Cabin))
dfTrain_fact$Sex <- as.numeric(as.factor(dfTrain_fact$Sex))
dfTrain_fact$Embarked <- as.numeric(as.factor(dfTrain_fact$Embarked))
dfTrain_fact$Age <- as.numeric(as.factor(dfTrain_fact$Age))
dfTrain_fact$Pclass <- as.numeric(as.factor(dfTrain_fact$Pclass))
dfTrain_fact$SibSp <- as.numeric(as.factor(dfTrain_fact$SibSp))
dfTrain_fact$Parch <- as.numeric(as.factor(dfTrain_fact$Parch))
dfTrain_fact$Sector <- as.numeric(as.factor(dfTrain_fact$Sector))
str(dfTrain_fact)
# Buscamos valores extremos en la variable Fare
ggplot(data = dfTrain_cat,
mapping = aes(x = 0,
y = Fare)
) +
geom_boxplot()
dfTrain.mujer <- dfTrain_fact[dfTrain_fact$Sex == "1",]$Survived
dfTrain.hombre <- dfTrain_fact[dfTrain_fact$Sex == "2",]$Survived
dfTrain.niños = dfTrain_fact[dfTrain_fact$Age == "1" | dfTrain_fact$Age == "2",]$Survived
dfTrain.adultos = dfTrain_fact[dfTrain_fact$Age != "1" & dfTrain_fact$Age != "2",]$Survived
alpha = 0.05
col.names = colnames(dfTrain_fact)
for (i in 1:ncol(dfTrain_fact)) {
if (i == 1)
cat("Variables que no siguen una distribución normal:\n")
if (is.integer(dfTrain_fact[,i]) | is.numeric(dfTrain_fact[,i])) {
p_val = ad.test(dfTrain_fact[,i])$p.value
if (p_val < alpha) {
cat(col.names[i])
# Format output
if (i < ncol(dfTrain_fact) - 1)
cat(", ")
if (i %% 3 == 0)
cat("\n")
}
}
}
fligner.test(Fare ~ Survived, data = dfTrain_fact)
t.test(dfTrain.hombre, dfTrain.mujer, alternative = "less")
t.test(dfTrain.adultos, dfTrain.niños, alternative = "less")
set.seed(14)
dfTrain_fact$Survived = as.factor(dfTrain_fact$Survived)
# Definimos train control
train_control <- trainControl(method='repeatedcv',
number=10,
repeats=5)
# Entrenamos el modelo
(train.rpart <- train(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked, #+ Sector,
data=dfTrain_fact,
method="rf",
metric='Accuracy',
trControl=train_control))
# Imprimimos las puntuaciones de cross-validation
summary(train.rpart)
summary(train.rpart$finalModel)
# Generamos la predicción
pred <- predict(train.rpart, dfTrain_fact)
plot(train.rpart)
plot(train.rpart$finalModel)
#Función optenida de https://shiring.github.io/machine_learning/2017/03/16/rf_plot_ggraph
tree_func <- function(final_model,
tree_num) {
# get tree by index
tree <- randomForest::getTree(final_model,
k = tree_num,
labelVar = TRUE) %>%
tibble::rownames_to_column() %>%
# make leaf split points to NA, so the 0s won't get plotted
mutate(`split point` = ifelse(is.na(prediction), `split point`, NA))
# prepare data frame for graph
graph_frame <- data.frame(from = rep(tree$rowname, 2),
to = c(tree$`left daughter`, tree$`right daughter`))
# convert to graph and delete the last node that we don't want to plot
graph <- graph_from_data_frame(graph_frame) %>%
delete_vertices("0")
# set node labels
V(graph)$node_label <- gsub("_", " ", as.character(tree$`split var`))
V(graph)$leaf_label <- as.character(tree$prediction)
V(graph)$split <- as.character(round(tree$`split point`, digits = 2))
# plot
plot <- ggraph(graph, 'dendrogram') +
theme_bw() +
geom_edge_link() +
geom_node_point() +
geom_node_text(aes(label = node_label), na.rm = TRUE, repel = TRUE) +
geom_node_label(aes(label = split), vjust = 2.5, na.rm = TRUE, fill = "white") +
geom_node_label(aes(label = leaf_label, fill = leaf_label), na.rm = TRUE,
repel = TRUE, colour = "white", fontface = "bold", show.legend = FALSE) +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
panel.background = element_blank(),
plot.background = element_rect(fill = "white"),
panel.border = element_blank(),
axis.line = element_blank(),
axis.text.x = element_blank(),
axis.text.y = element_blank(),
axis.ticks = element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
plot.title = element_text(size = 30))
print(plot)
}
tree_num <- which(train.rpart$finalModel$forest$ndbigtree == min(train.rpart$finalModel$forest$ndbigtree))
tree_func(final_model = train.rpart$finalModel, tree_num)
#Función https://stackoverrun.com/es/q/6546365
draw_confusion_matrix <- function(cm) {
layout(matrix(c(1,1,2)))
par(mar=c(2,2,2,2))
plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
title('CONFUSION MATRIX', cex.main=2)
# create the matrix
rect(150, 430, 240, 370, col='#3F97D0')
text(195, 435, 'Class1', cex=1.2)
rect(250, 430, 340, 370, col='#F7AD50')
text(295, 435, 'Class2', cex=1.2)
text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
text(245, 450, 'Actual', cex=1.3, font=2)
rect(150, 305, 240, 365, col='#F7AD50')
rect(250, 305, 340, 365, col='#3F97D0')
text(140, 400, 'Class1', cex=1.2, srt=90)
text(140, 335, 'Class2', cex=1.2, srt=90)
# add in the cm results
res <- as.numeric(cm$table)
text(195, 400, res[1], cex=1.6, font=2, col='white')
text(195, 335, res[2], cex=1.6, font=2, col='white')
text(295, 400, res[3], cex=1.6, font=2, col='white')
text(295, 335, res[4], cex=1.6, font=2, col='white')
# add in the specifics
plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
# add in the accuracy information
text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
cm <- confusionMatrix(pred, train.rpart$trainingData$.outcome, mode = "everything")
draw_confusion_matrix(cm)
dfTrain_cat$child <- cut(dfTrain$Age, c(0,13,100), labels=c("Child", "Adult"))
dfTrain_cat$child[dfTrain_cat$child == "1"] <- "Child"
install.packages(xelatex)
View(dfTrain)
